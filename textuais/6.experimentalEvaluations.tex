%==============================================================================
\chapter{Experimental Evaluations}\label{chap:experiments}
% Avaliação preliminar para a qualificação
%==============================================================================

In this chapter, we present the research questions and hypotheses investigated during the evaluation of our proposal. 
In addition to presenting the experimental design adopted and its conduction.
Section \ref{sec_experiments:preliminaryEval} presents the preliminary evaluation of ERText, which is focused on the assessment of tool features. Section \ref{sec_experiments:finalEval} describe the increments for the next evaluations, carried out until February 2022, which also includes the evaluation of learning features.
In the end, Section \ref{sec_experiments:lessons} draws the chapter's lessons.

%------------------------------------------------------------------------------
\section{Tool Features - Experiment 1} 
\label{sec_experiments:preliminaryEval}
%------------------------------------------------------------------------------

This section presents all the planning, conduction, discussion of the results obtained, threats to validity of the study, and the conclusions regarding the preliminary evaluation carried out to evaluate the first release of a stable prototype of the developed tool.

%######################################################
\subsection{Planning}
\label{ssec_experiments:preliminary_planning}
%######################################################

We carried out this preliminary evaluation from the replication of the experimental protocol performed in a previous study \cite{Lopes:2019}, which aimed to obtain evidence of the comparison from two approaches for modeling relational databases, one graphical and the other textual.
% This preliminary evaluation was carried out from the replication of the experimental protocol performed in a previous study \cite{Lopes:2019} and aims to obtain evidence from the comparison of two approaches for modeling relational databases, one graphical and the other textual.

We specified the following treatments:
\begin{enumerate} [label=\roman*.]
    \item Control treatment: the brModelo tool (graphical approach), and;
    \item Experimental treatment: the ERtext tool (textual approach).
\end{enumerate}
The purpose of this replication is to evaluate the feasibility of using a textual approach to support the teaching-learning process of conceptual modeling relational databases.

\textbf{Context:}
% The context of the experiment is characterized according to four dimensions:
We characterized the context of the experiment according to four dimensions:
\begin{enumerate}[label=\roman*.]
    \item Process: Process: it used an \textit{in-vitro} approach since we performed the tasks under controlled conditions;
    % Process: an \textit{in-vitro} approach was used, since the tasks were performed under controlled conditions.
    %In software engineering, most \textit{in-vitro} experiments are executed in universities or among selected groups of a software development organization \cite{Travassos:2003}.
    \item Subjects: undergrad students in Computer Science (CS) and Software Engineering (SE) programs;
    \item. Reality: the experiment addressed a real problem, \textit{i.e.} the difference in the effort spent of subjects in the conceptual modeling of relational databases; 
    %the artifacts quality produced and the subjects Perceived Usefulness (PU) using both approaches.
    \item Generality: we inserted this evaluation in a specific context, involving database modeling students.
    However, we can replicate the general ideas of this experiment in another set of subjects, approaches, or DSLs that support database designing. 
    % However, the general ideas of this experiment can be replicated in another set of subjects, approaches or DSLs that support database designing.
\end{enumerate}

\textbf{Research Questions (RQs):}
For the controlled experiment results discussion, we decided to formulate four RQs related to the activities performed in the execution of the protocol.
\begin{itemize}
    \item \textbf{RQ1.} Which approach requires the most effort spent on average during the modeling activity?
    \item \textbf{RQ2.} What is the quality level of the models produced using the graphical and textual approaches?
    \item \textbf{RQ3.} What is the subject's perception regarding the Perceived Ease of Use (PEoU) and Perceived Usefulness (PU) of the proposed DSL?
    \item \textbf{RQ4.} What is the subject's assessment concerning the representation of the ER modeling builders supported in the proposed DSL?
\end{itemize}

\textbf{Hypotheses Formulation:} 
% The first two RQs were taken into account. 
We have taken into account the first two RQs. 
Regarding \textbf{RQ1.} 
%the average effort spent required using each approach, our scientific hypotheses are as follows:
% we defined a two-sided hypotheses that measure the average effort spent between textual and graphical approaches during conceptual modeling. State the null (no difference) $H_0 : \mu Time_T = \mu Time_G$ and alternative (significant difference) $H_a : \mu Time_T \neq Time_G$ hypotheses.
\begin{itemize}
    \item \textbf{Null hypothesis:} $H_0 : \mu Time_T = \mu Time_G$: There is no difference in average effort spent measure between textual and graphical approaches during conceptual modeling.
    \item \textbf{Alternative hypothesis:} $H_{1} : \mu Time_T \neq \mu Time_G$: There is a significant difference in average effort spent measure between textual and graphical approaches during conceptual modeling.
\end{itemize}
Regarding \textbf{RQ2.} 
%the modeling effectiveness using each approach, our hypotheses are as follows:
in the same way, we stated two-sided hypotheses that measures the modeling effectiveness between textual and graphical approaches during conceptual modeling.
% The null (no difference) and alternative (significant difference) hypotheses are, respectively: 
% $H_0 : \mu Effectiveness_T = \mu Effectiveness_G$ and 
% $H_a : \mu Effectiveness_T \neq \mu Effectiveness_G$.
\begin{itemize}
    \item \textbf{Null hypothesis:} $H_0 : \mu Effectiveness_T = \mu Effectiveness_G$: There is no difference in effectiveness measures between textual and graphical approaches during conceptual modeling.
    \item \textbf{Alternative hypothesis:} $H_{1} : \mu Effectiveness_T \neq \mu Effectiveness_G$: There is a significant difference in effectiveness measures between textual and graphical approaches during conceptual modeling.
\end{itemize}

\textbf{Statistical Methods:} Unlike the first experiment, this replication included a change in the statistical methods adopted.
Previously, we have used the Shapiro-Wilk normality test and the paired T-test for dependent samples.
This was because the sample was smaller (27) than 30 elements.
However, for samples equal to or greater than this quantity, alternative tests are recommended~\cite{Triola:2018}.

For the effort, we chose the Kolmogorov-Smirnov test to verify normality and the Wilcoxon Signed-Rank test for paired samples to investigate the hypotheses using the time spent metric.
For the effectiveness tests, we have adopted the same statistical methods despite instead of using the time spent metric, another measure was necessary.
Thus, we have performed the F1 calculations, deriving from the harmonic mean of precision and recall metrics, for each model produced in both approaches.
% Thus, we have performed the F1 calculations, which is derived from the harmonic mean of \textit{Precision} and \textit{Recall} metrics, for each of the models produced in both approaches.
The F1 calculation \cite{Derczynski:2016} takes into account variables known as \textit{True Positives}, \textit{False Positives}, and \textit{False Negatives}.
\begin{description}
% \begin{inparadesc}
    \item \textbf{\textit{True Positives (TP)}}: Amount of elements correctly modeled using the approach.
    \item \textbf{\textit{False Positives (FP)}}: Amount of elements incorrectly modeled using the approach. 
    \item \textbf{\textit{False Negatives (FN)}}: Amount of elements not modeled using the approach.
% \end{inparadesc}
\end{description}
From the identification of the variables it is then possible to calculate the \textit{Precision}, \textit{Recall}, and \textit{F1} of each model according to these formulas:
% From the variables identification it is then possible to calculate the \textit{Precision}, \textit{Recall}, and \textit{F1} of each model according to these formulas:
\begin{description}
    \item \textbf{\textit{Precision (PR)}}: $\frac{TP}{TP~+~FP}$ 
    \hfill 
    \textbf{\textit{Recall (RE)}}:$\frac{TP}{TP~+~FN}$
    \hfill
    \textbf{\textit{F1-Score (F1)}}: $\frac{2~*~(PR~*~ RE)}{PR~+~RE}$
\end{description}

\textbf{Experiment Design:} Finally, Figure \ref{fig:designExp} presents the design of the controlled experiment performed. 
We followed the design of one factor with two treatments, where we blocked, balanced, and randomized the subjects, which carried out both treatments, featuring a paired comparison design.

\begin{figure}[!htb]
    \centering
    \caption{Experiment design.}
    \label{fig:designExp}
    \include{img/DesignExperiment}
    % \includegraphics[width=\columnwidth]{images/DesignExperimento.png}
    \fonte{Author.}
\end{figure}

%###########################################################
\subsection{Conduction}
\label{ssec_experiments:preliminary_conduction}
%###########################################################

\textbf{Preparation:} 
Initially, remote meetings were held between the researchers involved to define the planning and the mode of operation that should be adopted, in response to the current scenario of exception due to the worldwide pandemic.
As a result, activities were defined that should be adapted in relation to the first experiment, which was conducted in person.
In order to capture a significant sample for the object of study, it was decided to contact the professors responsible for teaching two courses of different undergraduate courses: Database (SE) and Database I (CS) in the first half of 2021.
% With the initial objectives aligned, the collaborating teachers made the disclosure of profile questionnaires (Google Forms) to the subjects.
Once the initial objectives aligned, the collaborating teachers disclosed the profile questionnaires (Google Forms) to the subjects.

We reused the four (4) instruments from the original experiment. 
The first two were modeling problems with similar levels of complexity, while the last two were qualitative assessments.
We decided that the activities would carry out remotely, respecting the health security protocols required (social distancing). 
For this purpose, we prepared a virtual machine with the tools installed, even as the instruments and supporting materials. 
This virtual machine should be accessed on the university's computers by the subjects using their institutional credentials.
% The four (4) instruments from the original experiment were reused. 
% The first two were modeling problems with similar levels of complexity, while the last two were of qualitative assessment.
% It was decided that the activities would be carried out remotely, respecting the health security protocols required (social distancing). 
% For this purpose, a virtual machine was prepared with the tools installed, as well as the instruments and supporting materials. 
% This virtual machine should be accessed on the university's computers by the subjects using their institutional credentials.

\textbf{Execution:} 
The profile form also served as a term of participation, since the presence in the experiment was voluntary.
With this information, then we have randomized the subjects to define the groups.
% With this information, the subjects were then randomized to define the groups.
We did not find wide discrepancies among the subjects' knowledge levels, demonstrating a homogeneous sample in general.
% We found that there were no major discrepancies between the levels of knowledge of the subjects, demonstrating that there was a homogeneous sample in general.
On the experiment day, the first activity carried out was a brief initial presentation.
Then, the training phase of the participants began.
During this phase, we have presented the two database modeling tools used in the experiment, providing an overview of the operation and answering possible questions that arose.
% During this phase, the two database modeling tools that would be used were presented, providing an overview of the operation and answering possible questions that arose.
The training included the display of videos demonstrating the tools, brModelo and our proposal, respectively.

Then, we start the modeling phase of the proposed problems.
All subjects accessed the virtual machines with the problems provided in PDF documents.
% When starting Instrument 1, all participants were informed with which tool they should develop the solution, thus respecting the groups to which they were part.
When starting Instrument 1, we informed which tool each participant should develop the solution, thus respecting the group to which one was part.
We asked the subjects to write down the start and end times of the tasks for each instrument they performed.
We stipulated no time limit for completion according to the subjects who completed the modeling task. 
We asked them to comply with the guidelines included in the support material for saving the generated artifacts.
% We stipulated no time limit for completion and, according to the subjects completed the modeling task, they were asked to comply with the guidelines included in the support material for saving the generated artifacts.
With the models saved, we informed the subjects that they should move on to the next task described in Instrument 2, although it was necessary to use the reverse approach to the one they had initially used.

At the end of the instruments that contained the modeling problems, we delivered the qualitative assessment instruments.
As the subjects had completed the tasks, then we had thanked and released them.
With the conclusion of the experiment by 33 subjects, we closed the evaluation and we performed the stage of result analysis.

%###########################################################
\subsection{Results Analysis}
\label{ssec_experiments:preliminary_resultAnalysis}
%###########################################################

We have performed all Kolmogorov-Smirnov and Wilcoxon Signed-Rank calculations with the support of the R language and the Gnumeric software. In parallel with the validation of a specialist in the statistics field and the aid of literature \cite{Triola:2018}.
% All Kolmogorov-Smirnov and Wilcoxon Signed-Rank calculations were performed with the support of the R language and the Gnumeric software, in parallel with the validation of a specialist in the field of statistics and the aid of literature \cite{Triola:2018}.

\textbf{Effort:} 
To answer \textbf{RQ1.} 
%regarding the effort to use the approaches, 
% the execution times were extracted from the instruments.
we have extracted the execution times from the instruments.
From the gross amount of the execution times, we have calculated the difference to perform the Kolmogorov-Smirnov normality test.
Because it is a statistical test, this technique has the product of measuring the $p$-value.
For this test, we adopted a significance level of $\alpha$~=~5\%.
It means that the p-value is less than 5\%, then we rejected a hypothesis that the distribution is normal.
% This means that the $p$-value is less than 5\% ($p$ < 0.05), a hypothesis that the distribution is normal should be rejected.

After calculations with the set of time differences, we reached a $p$-value of 0.26218.
As $p$-value > $\alpha$, we do not reject the null hypothesis, thus concluding that the data is normally distributed.
%\textit{i.e.}, 
In other words, the difference between the data sample and the normal distribution is not large enough to be statistically significant.
It is important to note that the higher the $p$-value, the more it supports a null hypothesis.
% In the case of the result obtained, the chance of type 1 error (rejecting a null hypothesis that is correct) is very high, and can be translated into 26.21\% (0.26218).
In the case of the result obtained, the chance of type 1 error (rejecting a correct null hypothesis) is very high and translates into 26.21\% (0.26218).
Once we performed the normality tests on the sample, we carried out the hypothesis test of the average effort regarding \textbf{RQ1.}
In the Wilcoxon Signed-Rank test for dependent samples, we used a significance level of $\alpha$~=~5\%, with which we reached a measure of 0.77948 for the $p$-value.
Because it is a two-tailed test, \textit{i.e.} it includes equality in its null hypothesis, this $p$-value shows not enough evidence to guarantee the rejection of the statement of $H_0: \mu Time_G = \mu Time_T$.
Therefore, we do not reject the null hypothesis that the approaches have no difference in average efforts, once according to the test, this difference is not statistically significant. 
Figure \ref{fig:boxplotTempo1} displays a box-plot with the variation of data observed through these data.

% \begin{figure}[!htb]
%     \centering
%     % \includegraphics[width=.9\columnwidth]{experimentResults/EsforcoBoxplot.pdf}
%     \include{figures/BoxPlotEsforco}
%     % \includesvg[width=.7\columnwidth]{figures/Effort}
%     \caption{Box-plot - Effort per treatments.}
%     \label{fig:boxplotTempo1}
% \end{figure}

\textbf{Effectiveness:} 
% To answer \textbf{RQ2.} regarding the effectiveness of the use of approaches
To answer \textbf{RQ2.} regarding the approaches' use effectiveness, we evaluated the artifacts produced by the subjects according to the established reference models\footnote{Available at: \url{https://doi.org/10.5281/zenodo.5454378}}. 
% In this evaluation, we used F1 from the area of pattern recognition and information retrieval. 
In this evaluation, we used F1 from the pattern recognition and information retrieval areas. 
F1 represents the combination of the observed accuracy and recallability of a result concerning a reference.
By definition, this combination refers to Precision and Recall metrics, where Precision is the proportion of recovered instances that are relevant and Recall is the proportion of relevant instances that are recovered.

In addition, we performed the Kolmogorov-Smirnov normality test to F1 for each model. 
After calculations with the set of differences in F1 for each model, we reached a $p$-value of 0.45459.
With this test result, the chance of type 1 error (rejecting a correct null hypothesis) can be very high, and can be translated into 45.45\% (0.45459).
As the $p$-value > $\alpha$, we do not reject the null hypothesis, thus realizing that the data is normally distributed
%, \textit{i.e.} the difference between the data sample and the normal distribution is not large enough to be statistically significant.
After the sample was tested for normality, we tested the second hypothesis defined in this experiment.
This time, in the Wilcoxon Signed-Rank test for dependent samples, we used again a significance level of $\alpha$~=~5\%, with which we reached a measure of 0.00197 for the $p$-value.
% By the original statement including an equality, also characterizing this test as two-tailed, it was concluded that the calculated $p$-value demonstrates that there is enough evidence to guarantee the rejection of the statement of the original null hypothesis, denoted as $H_0: \mu Effectiveness_G = \mu Effectiveness_T$.
By the original statement including equality, also characterizing this test as two-tailed, we concluded that the calculated $p$-value demonstrated enough evidence to guarantee the statement rejection of the original null hypothesis, denoted as $H_0: \mu Effectiveness_G = \mu Effectiveness_T$.
% Therefore, we reject the null hypothesis that the approaches have equal effectiveness, because according to the statistical test, the average difference of F1 among treatments is statistically significant.
Therefore, we rejected the null hypothesis that the approaches have equal effectiveness, once according to the statistical test, the average difference of F1 among treatments is statistically significant.
Table \ref{tab:ResultsModelosGeral} shows average measures of the evaluated values and also provides the possibility to carry out a dispersion analysis.
Based on these data, it was possible to verify that the textual approach has an advantage on average.

\rowcolors{1}{gray!15}{white}
\begin{table}[!htb]
    \caption{Measures of the conceptual data models produced in the experiment.}
    \label{tab:ResultsModelosGeral}
    \centering
    % \scriptsize
    \tiny
    \begin{tabular}{l|ccccc|ccccc}%{l|ccccc|ccccc}
    \bottomrule
    \rowcolor[HTML]{C0C0C0}
    \multicolumn{1}{l}{} &
    \multicolumn{5}{c|}{\textbf{Graphical Treatment}} &
    \multicolumn{5}{c}{\textbf{Textual Treatment}}
    \\ 
    \hline
    \rowcolor[HTML]{C0C0C0}
    \textbf{Measure} & \textbf{MI} & \textbf{RI} & \textbf{P(\%)} & \textbf{R(\%)} & \textbf{F1(\%)} &
    \textbf{MI} & \textbf{RI} & \textbf{P(\%)} & \textbf{R(\%)} & \textbf{F1(\%)}
    \\
    \hline
Maximum	&	47.00	&	36.00	&	96.67	&	92.31	&	88.00	&	56.00	&	46.00	&	97.22	&	97.87	&	91.36	\\
3\textdegree Quartile	&	31.00	&	28.00	&	92.31	&	63.04	&	76.32	&	34.00	&	31.00	&	94.74	&	75.00	&	82.86	\\
Median	&	26.00	&	24.00	&	88.89	&	56.41	&	68.85	&	30.00	&	29.00	&	90.63	&	65.96	&	74.63	\\
Average	&	27.52	&	24.12	&	87.69	&	57.96	&	69.13	&	30.88	&	27.45	&	89.49	&	63.65	&	73.16	\\
1\textdegree Quartile	&	23.00	&	20.00	&	84.21	&	50.00	&	62.50	&	26.00	&	23.00	&	87.88	&	51.06	&	63.01	\\
Minimum	&	18.00	&	16.00	&	72.73	&	41.03	&	52.46	&	19.00	&	15.00	&	72.73	&	31.91	&	45.45	\\
Variance	&	35.58	&	28.65	&	42.87	&	143.35	&	78.93	&	63.32	&	39.76	&	42.59	&	259.85	&	133.58	\\
SD &	5.97	&	5.35	&	6.55	&	11.97	&	8.88	&	7.96	&	6.31	&	6.53	&	16.12	&	11.56	\\
    \toprule
\end{tabular}
\begin{tablenotes}
    \scriptsize
    \centering
    \item \textit{Legend: MI = Modeled Items; RI = Relevant Items; P = Precision; R = Recall; F1 = F1-Score; SD = Standard Deviation.}
\end{tablenotes}
\fonte{Author.}
\end{table}

Figure \ref{fig:boxplotMedidaF1} box-plot graph displays the F1-Score for each treatment applied. 
Based on this graph, it is possible to verify the result obtained in the hypothesis test because the data dispersion does present a significant difference between the approaches.


\begin{figure}[!htb]
        \centering
        \caption{Box-plot - Effort per treatments.}
        \label{fig:boxplotTempo1}
        \include{img/BoxPlotEsforco1}
        \fonte{Author.}
\end{figure}


\begin{figure}[!htb]
        \centering
        \caption{Box-plot - F1 per treatments.}
        \label{fig:boxplotMedidaF1}
        \include{img/boxplotMedidaF1}
        \fonte{Author.}
\end{figure}

% \begin{figure}[!htb]
%     \centering
%     % \includegraphics[width=.9\columnwidth]{experimentResults/EfetividadeBoxplot.pdf}
%     \include{figures/boxplotMedidaF1}
%     % \includesvg[width=.7\columnwidth]{figures/F-Score}
%     \caption{Box-plot - F1 per treatments.}
%     \label{fig:boxplotMedidaF1}
% \end{figure}

\textbf{Qualitative Evaluation:} 
We took place with the analysis of the two instruments applied after the modeling tasks.
We have used the first instrument according to the TAM model \cite{Davis:1989,Persico:2014} to answer the \textbf{RQ3.} regarding the PEoU and PU.
% The first was used to respond to \textbf{RQ3.} regarding the PEoU and PU of treatments, according to the TAM model \cite{Davis:1989,Persico:2014}. 
It occurred through the selection of quality attributes described in ISO/IEC 25010.
% For this, we established a Likert scale from one to six points to measure the level of agreement of the subjects in the face of the statements exposed in the form.
For this, we established a Likert scale from one to six points to measure the subjects' agreement level in the face of the statements exposed in the form.
% This scale served to measure the level of agreement of the subjects in the face of the statements exposed in the form.
We have chosen an even number of alternatives to avoid possible neutral responses.
% Thus, the 7 quality attributes are grouped into three (3) categories being defined as follows:
Thus, we grouped the seven (7) quality attributes into three (3) defined categories as follows:

\begin{itemize}
% \begin{inparaenum}
    \item \textbf{Functionality} 
        \begin{itemize}
            \item \textit{Conformity}: ability level to which the software achieves specified goals with functional completeness, correctness, and appropriateness related to their functionalities.
        \end{itemize}
    \item \textbf{Usability}
        \begin{itemize}
            %Appropriateness recognisability
            \item \textit{Understandability}: ability level to which users can recognize whether the software is appropriate for their needs; 
            \item \textit{Learnability}: ability level to which the software enables the user to learn how to use it with effectiveness, efficiency in emergencies;
            \item \textit{Operability}: ability level to which the software is easy to operate, control, and appropriate to use.
        \end{itemize}
    \item \textbf{Quality in Use}
        \begin{itemize}
            \item \textit{Quality in Use}: ability level to which the software to achieve specified goals with effectiveness and efficiency with their users in specific contexts of use;
            % Performance Efficiency
            \item \textit{Productivity}: ability level to which the software to achieve specified goals with time-behavior, resources utilization and capacity, when performing its functions, meet requirements;
            \item \textit{Satisfaction}: ability level to which the software to achieve specified goals with usefulness, trust, pleasure and comfort with their users in specific contexts of use.
        \end{itemize}
        % \end{inparadesc}
% \end{inparaenum}
\end{itemize}

After summarizing the results, we observed a good acceptance by the subjects for the ERtext tool developed in this work.
Figure \ref{fig:inst3GERALExp} synthesizes the responses received for each quality attribute, showing a certain degree of similarity in the subjects' perception during the application of the treatments.
% A point that can be emphasized is the set of positive responses concerning the \textit{Productivity} and \textit{Operability} since in the hypothesis test related to the effort, the treatments demonstrated a similar need for execution time.
It is worth emphasizing a point that is the positive responses set concerning the \textit{Productivity} and \textit{Operability} since the hypothesis test related to the effort the treatments demonstrated a similar need for execution time.
According to the evaluations received, the most evident disadvantages of ERtext are manifested mainly concerning \textit{Understandability} and \textit{Learnability} quality attributes.

\begin{figure}[!htb]
    \centering
    \caption{Quality attributes per treatments.}
    \label{fig:inst3GERALExp}
    % \includegraphics[width=.9\columnwidth]{experimentResults/Inst3.png}
    \include{img/Inst3}
    \fonte{Author.}
\end{figure}

Concerning \textbf{RQ4.} on the assessment of DSL designers, we analyzed the artifacts of the 2nd qualitative assessment instrument.
This instrument listed the 8 ER modeling builders covered by DSL, arranged with a Likert scale from one to six points.
% Again, an even number was chosen on the scale to avoid neutral responses that could lead to a more subjective bias.
Again, we have chosen an even number on the scale to avoid neutral responses that could lead to a more subjective bias.
Figure \ref{fig:inst4GERALExp} compiles all the responses received. 
The builders related to Entities, Referential Attributes, Descriptive Attributes, and Cardinality were the best evaluated.
In contrast, all builders obtained at least one disagreement, highlighting the most disagreeing evaluations related with the current representations of Ternary Relationship and Self-relationship, unfortunately.

\begin{figure}[!htb]
    \centering
    \caption{Evaluation of DSL designers.}
    \label{fig:inst4GERALExp}
    % \includegraphics[width=0.9\columnwidth]{experimentResults/Inst4.png}
    \include{img/Inst4}
    \fonte{Author.}
\end{figure}

All data collected and used for statistical tests can be accessed in a public repository available at Zenodo\footnote{Available at: \url{https://doi.org/10.5281/zenodo.5454378}}.

%#######################################################
%#######################################################
\subsection{Threats to Validity}
\label{ssec_experiments:preliminary_threats}
%#######################################################
%#######################################################

In empirical studies, it is necessary to analyze and discuss the threats to validity even as the strategies used to mitigate them.
For the list of possible threats, we adopted the classification scheme published by Cook and Campbell \cite{Cook:1979}. 
% These threats followed the proposed pattern and were divided into four (4) categories, namely: construct validity, internal validity, external validity and conclusion validity.
These threats followed the proposed pattern, and we divided them into four (4) categories: construct validity, internal validity, external validity, and conclusion validity.

\textbf{Construct Validity}: 
Threats to construct validity concerns the experiment design and social factors.
\begin{enumerate}[label=\roman*.]
    \item \textit{Inappropriate Pre-operational Explanation}: is related to the fact that the experiment did not have the objective of the artifacts sufficiently defined before translation into measures or treatments. To mitigate this threat, the effort of each approach was compared, as well as their effectiveness carried out according to the Precision and Recall metrics; 
    
    \item The fact that the experiment did not have the objective of the artifacts sufficiently defined before translation into measures or treatments. To mitigate this threat the effort of each approach was compared, as well as their effectiveness carried out according to the Precision and Recall metrics; 
   
    \item \textit{Interaction of Different Treatments}: 
    if the subjects are involved in one more study, the controls of the different studies, can change and reverberate in the final results.
    To avoid this, we followed a paired design and, therefore, all subjects performed both treatments.
    However, learning issues during the execution of activities were not observed.
    We can verify this through the normality of the analyzed distributions of both samples: effort and effectiveness, demonstrating that the results remained similar as a whole with a low variation; 
    %\textit{i.e.} low standard deviation indicates that the data points tend to be very close to the mean. 
    
    % \item If the subjects are involved in one more study, the controls of the different studies, can change and reverberate in the final results. 
    % To avoid this, we followed a paired design, and therefore, all subjects performed both treatments. 
    % However, we do not observe learning issues among the execution of activities. 
    % This can be verified through the normality of the analyzed distributions of both samples: effort and effectiveness, demonstrating that the results remained similar as a whole with a low variation.
    
    \item \textit{Hypothesis Prediction}: 
    when subjects participate in an experiment they may try to find out what the objective or intended experiment result is. 
    This threat can bias the behavior, positively or negatively, depending on the anticipated hypothesis.
    To mitigate this threat, we do not inform the subjects about further details of the experiment; 
    
    \item We do not inform the subjects about further details of the experiment to mitigate the bias of the behavior, which can affect positively or negatively, depending on the anticipated hypothesis.
\end{enumerate}

\textbf{Internal Validity}: 
Threats to internal validity are the influences that can affect independent variables in correlation to causality without the researcher's knowledge.
\begin{enumerate} [label=\roman*.]
    \item \textit{History}: there is a risk when a specific period influences the experiment's performance. Due to the coronavirus pandemic, we conducted the entire evaluation in a controlled environment providing remote access for the subjects. 
    In addition, to soothe this threat, we carried out the entire process in March when, in general, students are not necessarily overwhelmed with academic activities;
    %\item There is a risk when a specific period influences the experiment's performance. Due to the coronavirus pandemic, we conducted the entire evaluation in a controlled environment providing remote access for the subjects.
    
    \item \textit{Maturation}: occurs concerning the subjects reacting in different ways over time. 
    Examples are when subjects are affected negatively (tiredness or boredom) or positively (learning) during the experiment execution.
    To alleviate this threat, we informed subjects from the beginning that they could terminate their participation at any time, without any penalty;
    %\item Sometimes the subjects could be affected negatively (tiredness or boredom) or positively (learning) during the experiment execution.
    %To alleviate this threat, we informed subjects from the beginning that they could terminate their participation at any time, without any penalty;
    
    \item \textit{Tests}: 
    if we have repeated the tests, the subjects can respond differently at other times, \textit{i.e.} they know how to perform the test. 
    %if the tests are repeated, the subjects may respond differently at different times, as they know how the test is performed. 
    If there is a need to become familiar with the tests, then we do not return the test results to the participant not to subsidize unintentional learning.  
    %If there is a need to familiarize yourself with the tests, the test results must not be returned to the subject, so as not to support unintentional learning. 
    There was no need for repetition of activities since they were performed once per participant in each treatment;
    
    \item \textit{Instrumentation}: is related to the artifacts used to perform experiment, such as data collection forms. 
    %If these are poorly designed, the experience is negatively affected.
    If the design of instruments is poor, then it negatively affects the experience.
    %To combat this threat, all artifacts were minimally adapted due to the design of the experiment (remote), and previously verified and validated in meetings between the researchers involved in this work.
    To combat this threat, we minimally adapted all artifacts due to the design of the experiment (remote) and previously verified and validated in meetings between the researchers involved in this work.
    In addition, we already had the first study with results counting 27 participants to validate the planned protocol for this experiment replication;
    
    \item We adapted all artifacts due to the design of the experiment (remote), which we verified and validated previously in meetings among the researchers involved in this work to avoid that the instrumentation of artifacts that can affect the execution.
    %All artifacts were minimally adapted due to the design of the experiment (remote), and previously verified and validated in meetings between the researchers involved in this work to avoid that the instrumentation of artifacts can be affect the execution.
    In addition, we already had the first study with results counting 27 participants to validate the planned protocol for this experiment replication.
\end{enumerate}

\textbf{External Validity}: 
% Threats to external validity are conditions related to experiment replication.
\begin{enumerate}[label=\roman*.]
    % \item \textit{Experiment Subjects}: the subjects selected for the experiment may not include a significant group for an study area.
    % Seeking to mitigate this threat, the experiment was carried out with undergrad students of SE and CS programs, and soon, inserted in the context of using the conceptual modeling of relational databases. 
    % In addition, the fact that the sample has more than 30 subjects is also a way of mitigating greater statistical threats in the analyzed area.
    \item The experiment was carried out with undergrad students of SE and CS programs, and soon, inserted in the context of using the conceptual database modeling seeking to mitigate the selection subjects from a significant group for an study area; 
    %In addition, the fact that the sample has more than 30 subjects is also a way of mitigating greater statistical threats in the analyzed area.
    %\item \textit{Subjects Interaction with the Evaluation Artifacts}: is related to the application of the evaluation artifacts of the experiment with the subjects.
    %Depending on the moment, this can affect the experimental results.
    %For example, if a questionnaire is answered a few days after the execution experiment, people tend to respond differently than they would do moments after the activities.
    %To mitigate this threat, participants were asked to answer the questionnaires and, before thanking them, we checked the submission of the instruments.
    \item We asked the participants to answer the questionnaires post-experiment and, before thanking them, we checked the submission of the instruments to avoid that the subjects' interaction with the evaluation artifacts can be affected the preliminary experimental results; 
    % \item \textit{Configuration and Treatment Interaction}: is related to the use of an unrepresentative configuration or material. 
    % To soften this threat, documentation was used based on templates and traditional models found in database teaching material. 
    % In addition, the artifacts were validated with two specialists in the field of SE.
    \item We used the documentation based on templates and traditional models found in database teaching material to soften an unrepresentative configuration and material.
\end{enumerate}

\textbf{Conclusion Validity}: 
% Threats to the validity of the conclusion are related to questions that affect the ability to infer a correct conclusion about the relationship between treatments and the result of an experiment.
\begin{enumerate} [label=\roman*.]
    % \item \textit{Low Statistical Power}:
    % To try mitigating this threat, some statistical methods were adopted, such as the Kolmogorov-Smirnov normality test, the Wilcoxon Signed-Rank Test as a hypothesis test for dependent samples. 
    % In addition, the tests were reviewed by an expert in the statistics field.
    \item We adopted some statistical methods such as the Kolmogorov-Smirnov normality test and the Wilcoxon Signed-Rank Test as a hypothesis test for dependent samples. We use them to try mitigating the low statistical power of our preliminary experimental results;
    % \item \textit{Reliability of Measurements}:
    % The reliability of the measurements used has a direct impact on the validity of the experiment as a whole. 
    % To mitigate this threat, it was adopted objective measurements that did not depend on subjective judgment (effort spent, measured in time, and F1).
    % On the other hand, the metrics used for the qualitative evaluation still served as a complementary input in the discussion of the results obtained, alongside with the indication of possible points of improvement in our proposal.
    \item We adopted objective measurements that did not depend on subjective judgment (effort spent, measured in time, and F1) to mitigate the measurement reliability threat.
    On the other hand, the metrics used for the qualitative evaluation still served as a complementary input in the results obtained discussion, alongside the indication of possible points of improvement in our proposal;
    % \textit{Experimental Environment}:
    % The experiment must be carried out in a controlled environment.
    % In order to mitigate this possible threat, we created copies of a virtual machine that were accessed by all subjects. 
    % We also instructed subjects that conversations could not take place during the entire execution of activities, in addition to not leaving the remote environment or access other electronic devices before the end of the tasks.
    \item We created copies of a virtual machine that all subjects accessed to guarantee that we experimented in a controlled environment.
    %We created copies of a virtual machine that were accessed by all subjects to guarantee that the experiment was carried out in a controlled environment.
    %Also, we instructed subjects that conversations could not take place during the entire execution of activities, in addition to not leaving the remote environment or access other electronic devices before the end of the tasks.
\end{enumerate}

%------------------------------------------------------------------------------
\section{Learning and Tool Features - Experiment 2 and Experiment 3}
\label{sec_experiments:finalEval}
%------------------------------------------------------------------------------

A meta da avaliação experimental final foi realizar dinâmicas similares com a descrita na Seção \ref{sec_experiments:preliminaryEval}. 
Contudo, desta vez o objetivo foi avaliar, além da linguagem, também a qualidade dos artefatos produzidos, a usabilidade e experiência dos participantes.
Sendo assim, a pretensão foi comparar as abordagens (textual vs gráfica) em avaliações mais profundas para as novas funcionalidades desenvolvidas da nossa ferramenta.
Isso implicou na criação e inclusão de novos instrumentos para a verificação dos artefatos gerados.

Houve um planejamento prévio para a utilização de um grupo composto por acadêmicos de uma classe de projeto e modelagem de banco de dados na UNIPAMPA.
Esta turma começou as aulas em novembro de 2021 e chegou ao término em março de 2022, possuindo inicialmente cinquenta (50) alunos matriculados.
Esta Seção descreve uma visão geral dos dois experimentos executados (\ac{ex2} e \ac{ex3}), suas execuções, resultados obtidos, discussão dos resultados e as ameaças identificadas.


%######################################################
\subsection{Experiment 2}
\label{ssec_experiments:Experiment2}
%######################################################

Em geral, o \ac{ex2} realizado replicou novamente o protocolo descrito na Seção \ref{ssec_experiments:preliminary_planning}.
Utilizamos os mesmos tratamentos, as mesmas perguntas de pesquisa e hipóteses.
Contudo, foi necessário que adotássemos métodos estatísticos diferentes em razão do tamanho das amostras.

A condução passou por uma preparação quase \textit{ipsis litteris} ao descrito na Seção \ref{ssec_experiments:preliminary_conduction}. 
Os convites foram feitos para uma turma de Engenharia de software e outra de Ciência da Computação, com cinquenta e quatro (54) respondentes.
Exposto isto, nesta nova execução obtivemos um total de vinte e cinco (25) sujeitos que aceitaram participar, ou seja, menos da metade dos respondentes.
Estes sujeitos realizaram as tarefas de forma remota em um ambiente previamente preparado pelos pesquisadores envolvidos.

Além de reusarmos os quatro (4) instrumentos de avaliação anteriores, ainda adicionamos um novo instrumento contendo um método não verbal para que os participantes relatassem suas emoções. 
Este método, chamado de Emocards, tem como base o conceito de Circumplexo de Afeto de Russell \cite{desmet:2001}.
Enquanto o Circumplexo de Russel divide as emoções humanas em quadrantes diferentes, o método Emocards o extende adicionando dezesseis (16) representações gráficas de faces humanas.
Estas representações são pares masculino/feminino, que são então associados a cada um dos octantes contidos nos quadrantes do circumplexo. 

O conceito do circumplexo e suas divisões é de que a cada dois (2) octantes se forme um quadrante que defina um estado de espírito. 
Os conjunto dos octantes 1 e 2 formam um quadrante que diz respeito as sensações de felicidade.
O conjunto dos octantes 3 e 4 definem um quadrante relacionado as sensações de relaxamento.
O conjunto de octantes 5 e 6 formam o quadrante onde a sensações de tristeza estão contidas.
Finalmentem, os octantes 7 e 8 constituem o quadrante que abrange sensações de irritabilidade.
A Figura \ref{fig:Octantes} mostra os quatro (4) estados de espírito que são previstos no circumplexo.

\begin{figure}[!htb]
        \centering
        \caption{The four (4) quadrants with the states of mind of the Russell circumplex.}
        \label{fig:Octantes}
        \include{img/Octantes}
        \fonte{Author.}
\end{figure}

A Figura \ref{fig:EmocardsMethod} apresenta o método Emocards inserido no Circumplexo de Afeto de Russel, mostrando os oito (8) octantes distribuídos nos quatro (4) estados de espírito, e com as dezesseis (16) representações gráficas associadas a eles. 

\begin{figure}[!htb]
        \centering
        \caption{Emocards method and its eight categories within Russell's circumplex.}
        \label{fig:EmocardsMethod}
        \includegraphics[width=0.5\textwidth]{img/Emocards.png}
        \fonte{\cite{Reijneveld:2003}.}
\end{figure}

A execução se deu em dezembro de 2021, ainda sem oferecer acesso aos participantes para que eles avaliassem os artefados produzidos pelos geradores implementados.
Os geradores foram desativados dentro do ambiente controlado que distribuído.
Isso se deu em razão de tentarmos replicar o experimento anterior visando comparar resultados e, por conta do tempo disponível ser limitado, isso poderia tornar somar mais uma ameaça aos resultados, já que demandaria mais esforço para realizar as tarefas adicionais.

%###########################################################
\subsubsection{Results Analysis}
%###########################################################

Esta seção apresenta os resultados obtidos da execução do \ac{ex2}.
Os dados utilizados estão disponíveis em um repositório\footnote{: link do repositório no Zenodo.} público na plataforma Zenodo.
Todos os testes estatísticos foram realizados com apoio da linguagem R em conjunto com a IDE RStudio. 
Os scripts para este experimento estão disponíveis de forma pública em um repositório\footnote{\url{https://github.com/JonnathanRiquelmo/misc/blob/main/some-scripts.r}}, portanto desta forma qualquer pessoa pode, além de consultar todos os dados brutos, executá-los localmente e verificar os resultados.

Levamos em consideração as mesmas hipóteses anteriores, relacionadas ao esforço (tempo) necessário e efetividade (qualidade) alcançada pelos modelos feitos.
Para a avaliação referente ao esforço foram utilizados o teste de normalidade Shapiro-Wilk, em razão da amostra ter menos de trinta (30) elementos, e o Teste T pareado para amostras dependentes, em que foi levado em consideração os tempos coletados durante a execução das atividades de modelagem do experimento. 

O método Shapiro-Wilk testa a hipótese nula de que uma distribuição é normal, mediante o cálculo do valor $W$, onde após é então verificado na tabela do teste\footnote{\url{ http://www.uel.br/projetos/experimental/pages/arquivos/Probabilidades\_Shapiro.pdf }} se ocorre a rejeição ou aceitação da hipótese. 
O cálculo do método Shapiro-Wilk é dado conforme a fórmula da Equação \ref{eq:Shapiro}: 

\begin{equation}
\label{eq:Shapiro}
%\[ 
W = \frac{\left(\sum_{i=1}^{n} a_ix_{(i)}\right)^2}{\sum_{i=1}^{n}\left(x_i -\overline{x}\right)} 
%\]
\end{equation}

Uma forma simplificada do Teste T pareado para amostras dependentes
se dá conforme a fórmula da Equação \ref{eq:TestT}:

\begin{equation}
\label{eq:TestT}
%\[ 
t = \frac{m}{s/\sqrt{n}} 
%\]
\end{equation}

Nesta fórmula o \textit{\textbf{m}} e o \textit{\textbf{s}} são a média e o desvio padrão da diferença (\textbf{\textit{d}}), respectivamente. 
O \textit{\textbf{n}} corresponde ao tamanho de \textit{\textbf{d}}, ou seja, o tamanho da amostra.
Este teste de hipótese é usado para comparar as médias de duas amostras relacionadas, ou seja, quando se possui dois valores (ou pares de valores) para uma mesma amostra. 
Contudo, para comparar as médias dos dois conjuntos de dados emparelhados, as diferenças entre todos os pares precisaram ser calculadas primeiro.
O nível de significância alfa ($\alpha$) utilizado foi de cinco por cento (5\%).

Para os testes da efetividade foram adotados os mesmos métodos estatísticos, porém ao invés do uso da métrica de tempo gasto nas atividades, foi necessário outra grandeza.
Sendo assim, foram realizados novamente cálculos para uma medida F1, conforme descrito anteriormente na Seção \ref{ssec_experiments:preliminary_planning}.


A partir dos valores brutos dos tempos foi calculada a diferença para ser possível realizar o teste de normalidade Shapiro-Wilk.
Por ser um teste estatístico, esta técnica tem como produto a medida do valor-$p$.
Para este teste foi adotado um nível de significância $\alpha$~=~5\%. 
Isso significa que se o valor-$p$ for menor que 5\% ($p$ < 0.05), a hipótese nula de que a distribuição é normal deve ser rejeitada.

Após os cálculos com o conjunto das diferenças dos tempos chegou-se a um valor-$p$ de 0.5991.
Como valor-$p$ \textgreater $\alpha$, a hipótese nula foi aceita, concluindo assim que os dados são normalmente distribuídos.
Em outras palavras, a diferença entre a amostra de dados e a distribuição normal não é grande o suficiente para ser estatisticamente significativa.

É importante ressaltar que quanto maior o valor-$p$, mais ele suporta uma hipótese nula. 
No caso do resultado obtido a chance de erro do tipo 1 (rejeitar uma hipótese nula que é correta) é muito alta, podendo ser traduzida em 59,91\% (0.5991).
Ainda em relação ao teste de normalidade, o valor de \textit{W} calculado foi de 0.968, estando dentro do intervalo aceito do valor crítico de 95\%. 
Isto significa que existe 95\% de chances da amostra ter origem em uma população normal.

Tendo sido a amostra testada quanto à sua normalidade, foi possível realizar o teste da primeira hipótese estabelecida neste experimento. 
No teste T pareado para amostras dependentes foi utilizado um nível de significância $\alpha$~=~5\%, com o qual se chegou a uma medida de 0.3492 para o valor-$p$. 

Por ser um teste bicaudal, ou seja, que inclui uma igualdade na sua hipótese nula, esse valor-$p$ não mostra evidências suficientes para garantir a rejeição da afirmativa de $H_0 : \mu Time_G = \mu Time_T$.
Em resumo, a média dos valores da abordagem gráfica (brModelo) é considerada similar à média da população da abordagem textual (ERtext).
Em outras palavras, a diferença entre as médias d brModelo e da ERtext não é grande o suficiente para ser estatisticamente significativa.
A Figura \ref{fig:boxplotTempo2} exibe um gráfico boxplot com a variação observada dos dados obtidos. 
% A \ref{tab:ResultsModelosGeral2} mostra os valores que possibilitam uma análise de dispersão. 


\begin{figure}[!htb]
        \centering
        \caption{Box-plot - Effort per treatments in \ac{ex2}.}
        \label{fig:boxplotTempo2}
        \include{img/BoxPlotEsforco2}
        \fonte{Author.}
\end{figure}

Para avaliar a hipotése referente a efetividade do uso das abordagens, os artefatos produzidos pelos sujeitos foram avaliados conforme os modelos de referência previamente estabelecidos.
Como dito, nesta avaliação foi utilizada a medida F1, uma medida proveniente da área de reconhecimento de padrões e recuperação de informação. 
Essa medida representa a combinação da precisão e revocabilidade observada de um resultado em relação à uma referência.

Após a obtenção dos valores F1 de cada modelo, foi realizado o teste de normalidade Shapiro-Wilk.
Após os cálculos com o conjunto das diferenças da medida F1 de cada modelo, chegou-se a um valor-$p$ de 0.5166.
Com este resultado obtido a chance de erro do tipo 1 (rejeitar uma hipótese nula que é correta) pode ser muito alta, podendo ser traduzida em 51,66\% (0.5166).

Como o valor-$p$ \textgreater $\alpha$, a hipótese nula foi aceita, constatando assim que os dados são normalmente distribuídos, isto é, a diferença entre a amostra de dados e uma distribuição normal não é grande o suficiente para ser estatisticamente significativa.

Após a amostra ser testada quanto à sua normalidade, foi realizado o teste da segunda hipótese definida, relativa a efetividade (qualidade) das abordagens. 
Desta vez, no teste T pareado para amostra dependentes, novamente foi utilizado um nível de significância $\alpha$~=~5\%, com o qual se chegou a uma medida de 0.2147 para o valor-$p$. 

Pela afirmativa original incluir uma igualdade, caracterizando também este teste como bicaudal, chegou-se a conclusão que o valor-$p$ calculado demonstra que não há evidências suficientes para garantir a rejeição da afirmativa da hipótese nula original, denotada como $H_0 : \mu Effectiveness_G = \mu Effectiveness_T$.
Logo, a hipótese nula de que as abordagens possuem efetividades iguais é aceita, pois segundo o teste a diferença média da medida F1 entre os tratamentos não é estatisticamente significativa.
A Figura \ref{tab:ResultsModelosGeral2} apresenta as medidas médias dos valores avaliados, e também fornecem a possibilidade para a realização de uma análise de dispersão.

\rowcolors{1}{gray!15}{white}
\begin{table}[!htb]
    \caption{Measures of the conceptual data models produced in \ac{ex2}.}
    \label{tab:ResultsModelosGeral2}
    \centering
    % \scriptsize
    \tiny
    \begin{tabular}{l|ccccc|ccccc}%{l|ccccc|ccccc}
    \bottomrule
    \rowcolor[HTML]{C0C0C0}
    \multicolumn{1}{l}{} &
    \multicolumn{5}{c|}{\textbf{Graphical Treatment}} &
    \multicolumn{5}{c}{\textbf{Textual Treatment}}
    \\ 
    \hline
    \rowcolor[HTML]{C0C0C0}
    \textbf{Measure} & \textbf{MI} & \textbf{RI} & \textbf{P(\%)} & \textbf{R(\%)} & \textbf{F1(\%)} &
    \textbf{MI} & \textbf{RI} & \textbf{P(\%)} & \textbf{R(\%)} & \textbf{F1(\%)}
    \\
    \hline
Maximum	&	49.00	&	44.00	&	93.75	&	92.50	&	91.67	&	65.00	&	45.00	&	94.74	&	92.68	&	91.14	\\
3\textdegree Quartile	&	46.00	&	39.00	&	88.89	&	85.42	&	86.02	&	47.00	&	38.00	&	89.19	&	87.80	&	87.06	\\
Average	&	41.08	&	35.20	&	85.88	&	78.57	&	81.74	&	44.64	&	36.48	&	83.24	&	83.35	&	82.81	\\
Median	&	43.00	&	36.00	&	86.05	&	77.50	&	81.32	&	44.00	&	36.00	&	85.37	&	83.67	&	84.71	\\
1\textdegree Quartile	&	36.00	&	31.00	&	84.78	&	75.00	&	79.12	&	40.00	&	34.00	&	81.82	&	79.59	&	78.72	\\
Minimum	&	27.00	&	23.00	&	71.43	&	57.50	&	68.66	&	34.00	&	32.00	&	58.46	&	69.39	&	69.47	\\
Variance	&	34.63	&	23.84	&	20.21	&	72.57	&	26.91	&	59.59	&	10.25	&	102.43	&	34.72	&	37.18	\\
SD	&	5.89	&	4.88	&	4.50	&	8.52	&	5.19	&	7.72	&	3.20	&	10.12	&	5.89	&	6.10	\\
    \toprule
\end{tabular}
\begin{tablenotes}
    \scriptsize
    \centering
    \item \textit{Legend: MI = Modeled Items; RI = Relevant Items; P = Precision; R = Recall; F1 = F1-Score; SD = Standard Deviation.}
\end{tablenotes}
\fonte{Author.}
\end{table}

O gráfico boxplot da Figura \ref{fig:boxplotMedidaF2} exibe uma representação visual da medida F1 dos tratamentos aplicados.
Com base neste gráfico é possível verificar o resultado obtido no teste de hipótese pois a dispersão dos dados não apresenta grande diferença entre as abordagens. 

\begin{figure}[!htb]
        \centering
        \caption{Box-plot - F1 per treatments in \ac{ex2}.}
        \label{fig:boxplotMedidaF2}
        \include{img/boxplotMedidaF2}
        \fonte{Author.}
\end{figure}

A avaliação referente aos atributos de qualidade para as ferramentas é apresentado na Figura \ref{fig:inst3GERALExp2}.
No geral, o resultado da avaliação feita pelos participantes foi proporcionalmente similar a obtida no experimento anterior. 
Os destaques desta vez ficaram por conta do atributo de satisfação para a abordagem textual, enquanto os atributos de conformidade e compreensão se sairam melhores na abordagem gráfica. 
Outro ponto a ser ressaltado é a diferença levemente menor no atributo de produtividade, mas ainda se mantendo em favor da abordagem textual.

\begin{figure}[!htb]
    \centering
    \caption{Quality attributes per treatments in \ac{ex2}.}
    \label{fig:inst3GERALExp2}
    \include{img/Inst3_2}
    \fonte{Author.}
\end{figure}

A avaliação referente aos construtores da DSL da abordagem textual, os resultados também seguiram a mesma proporção observada no primeiro experimento.
Isso nos leva a concluir que de fato é necessário, principalmente, uma reavaliação da representação dos relacionamentos ternários para torná-los mais fáceis de aprender, interpretar e utilizar.

\begin{figure}[!htb]
    \centering
    \caption{Evaluation of DSL designers in \ac{ex2}.}
    \label{fig:inst4GERALExp2}
    \include{img/Inst4_2}
    \fonte{Author.}
\end{figure}


Finalmente, chegamos aos instrumentos adicionados para tentar verificar o estado de espírito, ou as emoções causadas, pela execução das atividades com cada abordagem.
Os resultados das avaliações são dispostas em um circumplexo de Russell.
É possível observar que em relação ao uso da abordagem textual com a ferramenta ERtext houve uma concentração maior nos quadrantes que dizem respeito aos sentimento de alegria (octantes 1 e 2) e relaxamento (octantes 3 e 4).
Esses dois quadrantes concentraram um total de vinte (20) respondentes.
Ainda, houve a distribuição de três (3) partipantes que expressaram sentimentos relacionados a tristeza (octantes 5 e 6), e dois (2) sujeitos que demonstraram se identificarem com os Emocards relacionados ao quadrante que diz respeito a emoções de irritabilidade (octantes 7 e 8).
A Figura \ref{fig:Emocards1_alt} apresenta a distribuição dos sujeitos por cada octante previsto no método Emocards, e que utilizaram a abordagem textual.

\begin{figure}[!htb]
    \centering
    \caption{\ac{ex2} Emocards - ERtext.}
    \label{fig:Emocards1_alt}
    \include{img/Emocards1_alt}
    \fonte{Author.}
\end{figure}

A avaliação da abordagem gráfica, utilizando a ferramenta brModelo, apresentou uma distribuição semelhante.
Para os quadrantes que englobam sentimentos de alegria e relaxamento, foram dezenove (19) sujeitos.
O quadrante que representa sentimentos relacionados a triteza, foram quatro (4) sujeitos, enquanto que no quadrante respectivo a sensações de irritabilidade foram apenas dois (2) participantes.
A Figura \ref{fig:Emocards2_alt} apresenta a distribuição dos sujeitos por cada octante previsto no método Emocards, e que utilizaram a abordagem gráfica.


\begin{figure}[!htb]
    \centering
    \caption{\ac{ex2} Emocards - brModelo.}
    \label{fig:Emocards2_alt}
    \include{img/Emocards2_alt}
    \fonte{Author.}
\end{figure}

Levando em consideração que são abordagens que em sua essência são diametralmente opostas, acreditamos que a similaridade dos resultados observados pode ser um bom sinal.
Isso indica em um primeiro momento que nossa proposta alcança um nível similar de satisfação, semelhante ao de outra ferramenta já madura e amplamente estabelecida.
Contudo, para verificarmos mais a fundo isto foi então feito um terceiro experimento visando avaliar os geradores implementados, de uma forma mais qualitativa, uma vez que já possuímos material estatísticamente relevante e que suporta nossas conclusões em relação as hipóteses tratadas.

%######################################################
\subsection{Experiment 3}
\label{ssec_experiments:Experiment3}
%######################################################

O \ac{ex3} foi realizado na segunda metade de fevereiro de 2022.
Os vinte e cinto (25) participantes do \ac{ex2} foram novamente convidados a participarem.
Houve a aceitação de quinze (15) sujeitos.

Desta vez o protocolo original foi novamente modificado.
Nesta execução não procuramos realizar a medição do tempo ou da qualidade dos modelos produzidos.
Da mesma maneira, os participantes precisavam realizar a modelagem de dois (2) problemas simples, um com cada abordagem.

O ambiente deixou de ser uma máquina virtual, uma vez que houve a geração de um plugin completo para o Eclipse e disponibilizado publicamente .
Este plugin tinha como dependência de funcionamento apenas a instalação de uma IDE Eclipse e do Java, independentemente do sistema operacional usado.
De toda a forma as atividades ocorreram de forma remota, quando como nos outros experimentos os pesquisadores acompanharam de maneira online os sujeitos.

Os instrumentos também foram diferentes, já que nesta execução os instrumentos de avaliação dos contrutores e atributos de qualidade foram omitidos.
Nossa intenção era que os sujeitos avaliassem os artefatos gerados pelas ferramentas que suportavam as abordagens, nos diferentes níveis suportados.
Para isto utilizou-se uma escala likert para se obter a avaliação destes artefatos gerados em cada um dos níveis de modelagem (conceitual, lógico e físico).

Foi ainda reutilizado o método Emocards descrito anteriormente, visando entender o estado de espírito que o uso das ferramentas por completo podiam causar.
Também foram adicionadas uma série de perguntas abertas e, finalmente, um formulário com uma conhecida escala de usabilidade utilizada na engenharia de sistemas, nomeada \ac{sus}.
 
%###########################################################
\subsubsection{Results Analysis}
%###########################################################

No que diz respeito a avaliação dos artefatos relacionados aos níveis de modelagem, a Figura \ref{fig:ToolModelsEval} apresenta o resumo dos valores obtidos.
Em relação a classificação os modelos conceituais produzidos, houve uma melhor aceitação por parte da abordagem gráfica, na ferramenta brModelo.
Foram onze (11) avaliações com conceito máximo, em contraste a abordagem textual, utilizando a solução proposta ERtext.
A abordagem textual, além de ter menos avaliações máximas, totalizando sete (7), ainda teve avaliações com score dois (2), ou seja, baixas.
Para deixar registrado, a escala likert usada ia de um (1 - a pior avaliação) até seis (6 - a melhor avaliação), e enquanto o modelo conceitual da abordagem gráfica era apenas o diagrama, a abordagem textual era representado pelo modelo escrito e acompanhado de um equivalente gráfico que utilizava elementos \ac{uml}.

\begin{figure}[!htb]
    \centering
    \caption{Evaluation of Produced Artifacts - Both tools.}
    \label{fig:ToolModelsEval}
    \include{img/Eval_ToolModels}
    \fonte{Author.}
\end{figure}

Quanto a avaliação dos modelos lógicos gerados a partir dos modelos conceituais, houve uma equivalência maior, mas com uma pequena vantagem para a abordagem textual.
Em relação a avaliação dos modelos físicos, foi pedido que os códigos \ac{sql} em um \ac{dbms}, especificamente o PostgreSQL uma vez que o mesmo era utilizado de forma recorrente na classe de projeto e modelagem de banco de dados.

Os resultados dos modelos físicos mostraram uma vantagem leve para a abordagem textual, tendo ainda abordagem gráfica recebido avaliações com score (2), ou seja, considerando os modelos com qualidade baixa.

É importante salientar que a cada avaliação dos artefatos ainda era perguntado, de forma aberta, se existia critícas, elogios, dúvidas ou sugestões de melhoria quanto a representações observadas.
As respostas coletadas serviriam depois para uma análise qualitativa utilizando codificação.

Quanto a avaliação utilizando o método Emocards, os resultados são apresentados nas Figuras \ref{fig:Emocards4_alt} e \ref{fig:Emocards3_alt}.
Novamente houveram resultados muito aproximados, demonstrando que ambas as ferramentas conseguem despertar sentimentos e estados de espírito similares.

Nos Emocards relativos a abordagem textual (Figura \ref{fig:Emocards4_alt}), utilizando a ERtext, houve cinco (5) sujeitos que expressaram estarem no quadrante que engloba sentimentos de felicidade.
Outros nove (9) sujeitos demonstraram estarem no quadrante que envolve sentimentos relacionados a relaxamento, e apenas um (1) participante escolheu uma representação gráfica de face humana que era classificada no quadrante que compreende sentimentos de irritabilidade. 

\begin{figure}[!htb]
    \centering
    \caption{\ac{ex3} Emocards - ERtext.}
    \label{fig:Emocards4_alt}
    \include{img/Emocards4_alt}
    \fonte{Author.}
\end{figure}

Nos Emocards que dizem respeito a abordagem gráfica (Figura \ref{fig:Emocards3_alt}), utilizando a brModelo, houveram quatro (4) sujeitos que se declararam no quadrante que diz respeito a sentimentos de felicidade.
Outros oito (8) sujeitos demonstraram estarem no quadrante que envolve sentimentos relacionados a relaxamento.
Ainda, dois (2) participantes escolheram Emocards que são relacionados ao quadrante que expressa sentimentos de tristeza, e apenas um (1) ao quadrante que inclui os sentimentos de irritabilidade.

\begin{figure}[!htb]
    \centering
    \caption{\ac{ex3} Emocards - brModelo.}
    \label{fig:Emocards3_alt}
    \include{img/Emocards3_alt}
    \fonte{Author.}
\end{figure}

O formulário \ac{sus} 



% \begin{figure}[!htb]
%     \centering
%     \caption{SUS terceiro experimento - ERtext}
%     \label{fig:SUSERtext}
%     \include{img/SUS_ERtext}
%     \fonte{Author.}
% \end{figure}

% \begin{figure}[!htb]
%     \centering
%     \caption{SUS terceiro experimento - brModelo}
%     \label{fig:SUSbrModelo}
%     \include{img/SUS_brModelo}
%     \fonte{Author.}
% \end{figure}

% \begin{figure}[!htb]
%     \centering
%     \caption{SUS terceiro experimento - Ambas as tools}
%     \label{fig:SUS_tools}
%     \include{img/SUS_tools}
%     \fonte{Author.}
% \end{figure}

\begin{figure}[!htb]
    \centering
    \caption{BoxPlot SUS terceiro experimento - Ambas as tools}
    \label{fig:BoxPlotSUS_tools}
    \include{img/BoxPlotSUS}
    \fonte{Author.}
\end{figure}

\begin{figure}[!htb]
    \centering
    \caption{Grouped Bar Chart of \ac{sus} Values - Both tools.}
    \label{fig:GroupedBarSUS_tools}
    \include{img/GroupedBarSUS}
    \fonte{Author.}
\end{figure}

\rowcolors{1}{gray!15}{white}
\begin{table}[!htb]
    \caption{Measures of the \ac{sus} values in \ac{ex3}.}
    \label{tab:ResultsSUS}
    \centering
    \scriptsize
    % \tiny
    \begin{tabular}{l|ccccc|ccccc}%{l|ccccc|ccccc}
    \bottomrule
    \rowcolor[HTML]{C0C0C0}
    \multicolumn{1}{l}{} &
    \multicolumn{1}{c|}{\textbf{Graphical Treatment}} &
    \multicolumn{1}{c}{\textbf{Textual Treatment}}
    \\ 
    \hline
    \rowcolor[HTML]{C0C0C0}
    \textbf{Measure} & \textbf{SUS Final Score} & \textbf{SUS Final Score}
    \\
    \hline
Maximum	&	100.00	&	100.00		\\
3\textdegree Quartile	&	85.00	&	92.50	\\
Average	&	76.83	&	78.50	\\
Median	&	80.00	&	75.00	\\
1\textdegree Quartile	&	73.75	&	67.50	\\
Minimum	&	37.50	&	50.00	\\
Variance	&	248.63	&	241.79	\\
SD	&	15.77	&	15.55	\\
    \toprule
\end{tabular}
\begin{tablenotes}
    \scriptsize
    \centering
    \item \textit{Legend: SD = Standard Deviation.}
\end{tablenotes}
\fonte{Author.}
\end{table}

- FAZER MAPEAMENTO ENTRE AVALIAÇÃO QUALITATIVA (SUJEITOS X RESPOSTAS) E EMOCARDS

- Um paragrafo para cada code e tentar contrapor 

- Trabalho futuro: Definir esquema de cores personalizada para os modelos criados

- Corrigir restante do texto principalmente quanto a tempos verbais

\cleardoublepage
%------------------------------------------------------------------------------
\section{Chapter Lessons}
\label{sec_experiments:lessons}
%------------------------------------------------------------------------------

This chapter presented a preliminary controlled experiment (Experiment 1) replication with a sample of 33 subjects evaluating ERtext, a proposed textual \ac{dsl} tool for \acp{db} conceptual modeling. 
We compared the ERtext with the brModelo, a graphical \ac{dsl} well-known in Software Engineering ER lectures. 
With the results obtained, it was possible to answer the experiment's four RQs, as well as the two associated hypotheses.
In this sense, we can say that we investigated three main aspects of our \ac{dsl}: effort, effectiveness, and quality in use.

From the analysis, it is possible to highlight the following aspects:

\item \textbf{Effort:} The computed average difference states that there are no differences between the approaches, \textit{i.e.}, one approach is not better than the other. 

\item \textbf{Effectiveness:} Through the statistical test we reject the null hypothesis that the approaches are equally effective. 
When comparing the box-plot graphs produced, it is possible to observe a slight advantage for the textual approach. 
In the first experiment (Experiment 1), the result was different since the tests indicated that there was no significant difference. 
We believe that the biggest reason for this event is that all participants in this replication are undergraduate students at the very beginning of the academy program, basically without any more previous experience with graphic modeling tools. 
In the first experiment, there were, in addition to these, master and doctoral students. 
We also do not discard possible influences caused by the fact that the experiment was conducted remotely in the pandemic context.

\item \textbf{Qualitative comparison between treatments:} We observed a certain balance between treatments, but with a positive evaluation for ERtext regarding the ``Productivity'' and ``Operability'' attributes.
Because it was the first time that the subjects had contact with our grammar, and also considering the first release of our DSL and the negative feedback also collected, we conclude that ERtext is on the rails for achieving better productivity indexes.

We also collected qualitative feedback from subjects. 
As a result, there are some improvements regarding the DSL design that need to be revised, in particular to the ternary relationships and self-relationships.
Since the continuity of DSL development is foreseen, the execution of a possible refactoring, and also the implementation of new ER builders, is a natural step for its software evolution.
From the preliminary experimental results, we conclude that there is feasibility and good perspectives for the motivating context, \textit{i.e.}, as a tool for teaching ER modeling with the differential of adopting a textual approach for conceptual \ac{db} modeling in classrooms instead of a graphical notation.

% Finalmente, nós esperamos complementar as lições deste capítulo em breve com a avaliação experimental que ainda será realizada.
Finally, we hope to supplement the lessons in this chapter shortly by carrying out the experimental evaluation yet.



% RESULTADOS DO EXPERIMENTO 2

% \textbf{NORMALIDADE DAS AMOSTRAS}\\
% Método: \textbf{Shapiro-Wilk} (amostra com menos de 30 elementos)\\~\\

% \textbf{TEMPO}\\
% \textbf{P-value	= 0.5991} com com $\alpha$~=~5\%  (Significance level)\\
% Sample size (n)	25\\
% Os testes de Shapiro-Wilk não mostraram um desvio significativo da normalidade, W(25) = 0,968, p = 0,5991\\
% Ou seja, o conjunto da diferença entre os valores dos tempos de execução de cada tratamento (textual X gráfico) pode ser cosiderado uma \textbf{distribuição normal}.
% \\~\\ 
% \textbf{MEDIDA-F}\\
% \textbf{P-value = 0.5166} com $\alpha$~=~5\% (Significance level)\\
% Sample size (n)	25\\
% Os testes de Shapiro-Wilk não mostraram um desvio significativo da normalidade, W(25) = 0,965, p = 0,5166\\
% Ou seja, o conjunto da diferença entre os valores das medidas-F de cada tratamento (textual X gráfico) pode ser cosiderado uma \textbf{distribuição normal}.


% \\~\\

% \textbf{TESTE DE HIPÓTESE}\\
% Método: \textbf{Teste T pareado (amostras dependentes, com menos de 30 elementos)}\\~\\
% \textbf{MEDIDA-F}\\
% P-value	= 0.2147 com $\alpha$~=~5\% (Significance level)\\ 
% Sample size (n)	25\\
% Como o valor de P \textgreater $\alpha$, \textbf{H0 não pode ser rejeitada}.
% A média dos valores da brModelo é considerada igual à média da população da ERtext.
% Em outras palavras, a \textbf{diferença} entre as médias d brModelo e da ERtext \textbf{não é grande o suficiente para ser estatisticamente significativa}.\\
% \textbf{Lembrete: Um resultado de não significância não pode provar que H0 está correta, apenas que a suposição nula não pode ser rejeitada, ou seja, não se aceita H0 mas sim deixa-se de rejeitar H0.}
% \\~\\ 
% \textbf{TEMPO}\\
% P-value = 0.3492 com $\alpha$~=~5\% (Significance level)\\
% Sample size (n)	25\\
% Como o valor de P \textgreater $\alpha$, \textbf{H0 não pode ser rejeitada}.
% A média dos valores da brModelo é considerada igual à média da população da ERtext.
% Em outras palavras, a \textbf{diferença} entre as médias d brModelo e da ERtext \textbf{não é grande o suficiente para ser estatisticamente significativa}.